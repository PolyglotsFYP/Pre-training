{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PolyglotsFYP/Pre-training/blob/main/data_cleaning/Data_Cleaning-CulturaX.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ilsQCD7zQuHx"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install datasets\n",
        "!pip install fasttext\n",
        "!pip install nltk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "lrz2WDGxQGkt",
        "outputId": "81903353-c302-44b7-9750-af009885f20e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset size : 753655\n",
            "Time for cleaning the data in seconds: 3692.41078\n",
            "Time for cleaning the data in minutes: 61.54018\n",
            "Total sentences : 8637030\n",
            "Sucessfully created\n"
          ]
        }
      ],
      "source": [
        "#on GPU215\n",
        "import string\n",
        "import re\n",
        "import fasttext\n",
        "from  datasets import load_dataset\n",
        "from nltk.tokenize import sent_tokenize\n",
        "import nltk\n",
        "import time\n",
        "\n",
        "nltk.download('punkt')\n",
        "CulturaX_sin = load_dataset(\"uonlp/CulturaX\",\n",
        "                  \"si\",token='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')\n",
        "\n",
        "file_out= open('train-CulturaX.si-1.txt', 'w', encoding='utf8')\n",
        "\n",
        "sent_ending_suffixes=[\"...\", \"///\", \"???\", \"..\", \"//\"]\n",
        "bible_books={\"උත්පත්ති\",\"නික්මයාම\",\"ලෙවී කථාව\",\"ගණන් කථාව\",\"ද්වීතීය කථාව\",\"යෝෂුවා\",\"විනිශ්චයකාරයන්ගේ පොත\",\"රූත්ගේ කථාව\",\"1 සාමුවෙල්\",\"2 සාමුවෙල්\",\"1 රාජාවලිය\",\"2 රාජාවලිය\",\"1 ලේකම්\",\"2 ලේකම්\",\"එස්රා\",\"නෙහෙමියා\",\"එස්තර්\",\"යෝබ්\",\"ගීතාවලිය\",\"හිතෝපදේශ\",\"දේශනාකාරයා\",\"සාලමොන්ගේ ගීතිකා\",\"යෙසායා\",\"යෙරෙමියා\",\"විලාප ගී\",\"එසකියෙල්\",\"දානියෙල්\",\"හොෂෙයා\",\"යෝවෙල්\",\"ආමොස්\",\"ඔබදියා\",\"යෝනා\",\"මීකා\",\"නාහුම්\",\"හබක්කුක්\",\"ශෙපනියා\",\"හග්ගයි\",\"සෙකරියා\",\"මලාකි\",\"ශු. මතෙව්\",\"ශු. මාර්ක්\",\"ශු. ලූක්\",\"ශු. යොහන්\",\"ක්රිරයා\",\"රෝම\",\"1 කොරින්ති\",\"2 කොරින්ති\",\"ගලාති\",\"එපීස\",\"පිලිප්පි\",\"කොලොස්සි\",\"1 තෙසලෝනික\",\"2 තෙසලෝනික\",\"1 තිමෝති\",\"2 තිමෝති\",\"තීතස්\",\"පිලෙමොන්\",\"හෙබ්රෙනව්\",\"යාකොබ්\",\"1 පේතෘස්\",\"2 පේතෘස්\",\"1 යොහන්\",\"2 යොහන්\",\"3 යොහන්\",\"යූදස්\",\"එළිදරව්\"}\n",
        "\n",
        "# LID model\n",
        "# si - Lnaguage code for Sinhala\n",
        "LID='si'\n",
        "pretrained_lang_model = \"lid.176.bin\"\n",
        "model = fasttext.load_model('{}'.format(pretrained_lang_model))\n",
        "\n",
        "#regexp pattern\n",
        "url_pattern = r'https?://\\S+\\.html'\n",
        "num_prefix_pattern=r'^\\(\\d+\\)\\s|^\\d+\\.|^\\d+\\:'\n",
        "\n",
        "def get_lid(text):\n",
        "    predictions = model.predict(text, k=1)\n",
        "    lang_code = predictions[0][0].strip().split('__')[-1]\n",
        "    #prob = predictions[1][0]\n",
        "    return lang_code\n",
        "\n",
        "#print first example\n",
        "# print(CulturaX_sin['train'][0][\"text\"])\n",
        "\n",
        "#num_examples=349220,\n",
        "print('Dataset size : {}'.format(len(CulturaX_sin['train'])))\n",
        "\n",
        "#flag\n",
        "hasReachedLimit=False\n",
        "\n",
        "count=0\n",
        "used_sentences=set()\n",
        "#print Si Text\n",
        "\n",
        "start = time.time()\n",
        "\n",
        "for example in range(len(CulturaX_sin['train'])):\n",
        "    CulturaX_sin_example = CulturaX_sin['train'][example]\n",
        "\n",
        "    lines = CulturaX_sin_example[\"text\"].split('\\n')[2:] #Remove repetition words දැන් අපේ වගකීම මුළු මනුෂ්‍ය සංහතිය ම වෙනුවෙන් | Sinhala story Blog (2)දැන් අපේ වගකීම මුළු මනුෂ්‍ය සංහතිය ම වෙනුවෙන්\n",
        "\n",
        "    for index in range(len(lines)):\n",
        "        line = lines[index]\n",
        "        line = re.sub(url_pattern, ' ', line)  # replace urls within text\n",
        "        sentences=sent_tokenize(line)\n",
        "\n",
        "        # sentence filtration\n",
        "        sentences = [s for s in sentences if len(s.split()) > 6 and get_lid(s) == LID and s[-3:] not in sent_ending_suffixes and s[-2:] not in sent_ending_suffixes and len(bible_books.intersection(set(s.split())))==0]\n",
        "\n",
        "        for sentence in sentences:\n",
        "            sentence = re.sub(num_prefix_pattern, '', sentence).strip().strip('\"')\n",
        "\n",
        "        if len(used_sentences.intersection([sentence])) == 0:\n",
        "            used_sentences.add(sentence)\n",
        "            #sentence = sentence.replace(\"\\u0dca\\u0dbb\", \"\\u0DCA\\u200D\\u0dbb\") #දුම්රිය> දුම්‍රිය\n",
        "            # line=line.replace(\"\\u0dca\\u0020\\u0dba\", \"\\u0DCA\\u200D\\u0dba\") #මෙන්ය > මෙන්ya\n",
        "            file_out.write('{}\\n'.format(sentence))\n",
        "            count+=1\n",
        "\n",
        "end = time.time()\n",
        "\n",
        "print(f\"Time for cleaning the data in seconds: {end-start:.5f}\")\n",
        "print(f\"Time for cleaning the data in minutes: {(end-start)/60:.5f}\")\n",
        "\n",
        "print('Total sentences : {}'.format(count))\n",
        "print('Sucessfully created')\n",
        "file_out.close()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fewrZ1eYQnn1"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN3PckDbwWklRKQ3pabzwt/",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}